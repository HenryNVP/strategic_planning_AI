@startuml strategic_ai_sequence
title Strategic Planning AI â€“ Key Runtime Flows

skinparam shadowing false
skinparam defaultFontName "Segoe UI"

actor User
participant "Mock Tester UI\n(browser)" as UI
participant "Agent API\n(/api/v1/...)" as AGENT
participant "LangGraph Orchestrator" as LANGGRAPH
participant "RAG Proxy\n(/api/v1/documents)" as DOC_PROXY
participant "RAG API\n(/embed, /query)" as RAG_API
database "Postgres\n(pgvector)" as PG
participant "Embeddings Service\n(Gemini)" as EMB
participant "LLM Provider\n(GPT / Gemini)" as LLM
participant "Langfuse / Metrics" as OBS

== Guest Session bootstrap ==
User -> UI : Open /ui test console
UI -> AGENT : POST /auth/session\n(no Authorization header)
AGENT -> PG : get_or_create_guest_user\n(sqlmodel)
AGENT -> PG : insert session row + checkpoint thread
AGENT --> UI : session token (JWT)
UI -> OBS : store token locally (browser)

== Document ingestion ==
UI -> DOC_PROXY : POST /documents/upload\n(file, file_id?)
DOC_PROXY -> RAG_API : POST /embed\n(attach JWT)
RAG_API -> Embeddings : generate chunk embeddings
RAG_API -> PG : insert chunks + vectors
RAG_API --> DOC_PROXY : {status, file_id}
DOC_PROXY --> UI : success message

== Chat with RAG context ==
loop per user turn
  User -> UI : type prompt
  UI -> AGENT : POST /chatbot/chat\nAuthorization: session token
  AGENT -> LANGGRAPH : invoke(session_id, messages)
  group retrieve context
    LANGGRAPH -> RAG_API : POST /query\n{query, file_ids, JWT}
    RAG_API -> PG : similarity_search (pgvector)
    PG --> RAG_API : ranked vectors + metadata
    RAG_API --> LANGGRAPH : contextual passages
  end
  LANGGRAPH -> LLM : prompt(messages + context)
  LLM --> LANGGRAPH : assistant reply
  LANGGRAPH -> PG : persist checkpoint state
  LANGGRAPH --> AGENT : message list
  AGENT --> UI : ChatResponse (messages)
  AGENT -> OBS : emit metrics / traces
end

== Optional stream ==
UI -> AGENT : POST /chatbot/chat/stream
AGENT -> LANGGRAPH : astream(...)
loop SSE chunks
  LANGGRAPH --> AGENT : token chunk
  AGENT --> UI : data: {content, done?}
end

== History management ==
UI -> AGENT : GET /chatbot/messages
AGENT -> LANGGRAPH : load_state(thread_id)
LANGGRAPH -> PG : fetch checkpoints
PG --> LANGGRAPH : state snapshot
LANGGRAPH --> AGENT : conversation history
AGENT --> UI : prior messages

UI -> AGENT : DELETE /chatbot/messages
AGENT -> PG : delete from checkpoint_* tables
AGENT --> UI : confirmation

== Monitoring ==
AGENT -> OBS : Prometheus metrics, Langfuse traces
RAG_API -> OBS : service metrics / logs

@enduml
